{"metadata":{"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\n\n\n#Importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.feature_selection import RFE # feature elimination\nfrom sklearn.ensemble import ExtraTreesRegressor #importing estimator\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.metrics import mean_absolute_error\n\nimport tensorflow as tf\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.utils import np_utils\nfrom keras.constraints import maxnorm\n\n\n\n","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0861d1a7a816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"],"ename":"ModuleNotFoundError","evalue":"No module named 'keras'","output_type":"error"}]},{"cell_type":"code","source":"# fix random seed for reproducibility\nseed = 7\nnp.random.seed(seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing dataset\ndataframe = pd.read_csv(\"propulsion.csv\")\n\ndataframe = dataframe.round(3)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assign names to Columns\ndataframe.columns = ['lever_position', 'ship_speed', 'gt_shaft', \n                     'gt_rate', 'gg_rate', 'sbp_torque', 'pp_torque',\n                     'hpt_temp',  'gt_c_o_temp', \n                     'hpt_pressure',  'gt_c_o_pressure',\n                     'gt_exhaust_pressure', 'turbine_inj_control', \n                     'fuel_flow', 'gt_c_decay',  'gt_t_decay']\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#identify missing values\nmissing_values =dataframe.isnull().sum()\nmissing_values\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting data insights\npd.set_option('display.max_columns', 1000)\nprint(dataframe.head()) \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Statistical Description:\", dataframe.describe())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape:\", dataframe.shape)\nprint(\"Data Types:\", dataframe.dtypes)\n\ndataset = dataframe.values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting dataset \nX = dataset[:,0:15]\nY1 = dataset[:,14] #gt_c_decay\nY2 = dataset[:,15] #gt_t_decay\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feature Selection for gt_c_decay\nestimator = ExtraTreesRegressor()\nrfe = RFE(estimator, 3)\nfit = rfe.fit(X, Y1)\n\nprint(\"Number of Features: \", fit.n_features_)\nprint(\"Selected Features: \", fit.support_)\nprint(\"Feature Ranking: \", fit.ranking_) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feature Selection for gt_t_decay\nestimator = ExtraTreesRegressor()\nrfe = RFE(estimator, 3)\nfit = rfe.fit(X, Y2)\n\nprint(\"Number of Features: \", fit.n_features_)\nprint(\"Selected Features: \", fit.support_)\nprint(\"Feature Ranking: \", fit.ranking_) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#histogram of dataframe\n\ndataframe.hist()\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split Data to Train and Test\nX_Train, X_Test, Y1_Train, Y1_Test = train_test_split(X, Y1, test_size=0.2)\n\nnum_instances = len(X)\n\nmodels = []\nmodels.append(('LiR', LinearRegression()))\nmodels.append(('Ridge', Ridge()))\nmodels.append(('Bag_Re', BaggingRegressor()))\nmodels.append(('RandomForest', RandomForestRegressor()))\nmodels.append(('ExtraTreesRegressor', ExtraTreesRegressor()))\nmodels.append(('KNN', KNeighborsRegressor()))\nmodels.append(('CART', DecisionTreeRegressor()))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluations\nresults = []\nnames = []\nscoring = []\n\nfor name, model in models:\n    # Fit the model\n    model.fit(X_Train, Y1_Train)\n    \n    predictions = model.predict(X_Test)\n    \n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\n    score = explained_variance_score(Y1_Test, predictions)\n    mae = mean_absolute_error(predictions, Y1_Test)\n   \n    # print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    results.append(mae)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, score, mae)\n    print(msg)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # Split Data to Train and Test\nX_Train, X_Test, Y2_Train, Y2_Test = train_test_split(X, Y2, test_size=0.2)\n\nnum_instances = len(X)\n\nmodels = []\nmodels.append(('LiR', LinearRegression()))\nmodels.append(('Ridge', Ridge()))\nmodels.append(('Bag_Re', BaggingRegressor()))\nmodels.append(('RandomForest', RandomForestRegressor()))\nmodels.append(('ExtraTreesRegressor', ExtraTreesRegressor()))\nmodels.append(('KNN', KNeighborsRegressor()))\nmodels.append(('CART', DecisionTreeRegressor()))\n\n# Evaluations\nresults = []\nnames = []\nscoring = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, model in models:\n    # Fit the model\n    model.fit(X_Train, Y2_Train)\n    \n    predictions = model.predict(X_Test)\n    \n    # Evaluate the model\n    score = explained_variance_score(Y2_Test, predictions)\n    mae = mean_absolute_error(predictions, Y2_Test)\n   \n # print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    \nresults.append(mae)\nnames.append(name)\nmsg = \"%s: %f (%f)\" % (name, score, mae)\nprint(msg)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now for  using Deep Learning Models to predict values  \n    \n# Split Data to Train and Test\nX_Train, X_Test, Y1_Train, Y1_Test = train_test_split(X, Y1, test_size=0.3)\n\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create model\nmodel = Sequential()\nmodel.add(Dense(6, input_dim=15, init='uniform', activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(4, init='uniform', activation='relu', kernel_constraint=maxnorm(3)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(2, init='uniform', activation='relu'))\nmodel.add(Dense(1, init='uniform', activation='relu'))\n\n# Compile model\nmodel.compile(loss='mean_absolute_error', optimizer='adam')\n\n# Fit the model\nmodel.fit(X_Train, Y1_Train, epochs=100, batch_size=10)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\nscores = model.evaluate(X_Test, Y1_Test)\nprint(\"score: %.2f%%\" % (100-scores))\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split Data to Train and Test\nX_Train, X_Test, Y2_Train, Y2_Test = train_test_split(X, Y2, test_size=0.3)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create model\nmodel = Sequential()\nmodel.add(Dense(6, input_dim=15, init='uniform', activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(4, init='uniform', activation='relu', kernel_constraint=maxnorm(3)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(2, init='uniform', activation='relu'))\nmodel.add(Dense(1, init='uniform', activation='relu'))\n\n# Compile model\nmodel.compile(loss='mean_absolute_error', optimizer='adam')\n\n# Fit the model\nmodel.fit(X_Train, Y2_Train, epochs=100, batch_size=10)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\nscores = model.evaluate(X_Test, Y2_Test)\nprint(\"score: %.2f%%\" % (100-scores))\n","metadata":{},"execution_count":null,"outputs":[]}]}